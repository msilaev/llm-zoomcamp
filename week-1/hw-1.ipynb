{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8913c5",
   "metadata": {},
   "source": [
    "## LLM zoomcamp Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6cd704",
   "metadata": {},
   "source": [
    "### Q 1 \n",
    "\n",
    "Run Elastic Search 8.17.6, and get the cluster information. What's the version.build_hash value?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c83312",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker stop $(docker ps -q)\n",
    "docker rm $(docker ps -aq)\n",
    "\n",
    "docker pull docker.elastic.co/elasticsearch/elasticsearch:8.17.6\n",
    "\n",
    "docker run -p 9200:9200 -e \"discovery.type=single-node\" -e \"ES_JAVA_OPTS=-Xms1g -Xmx1g\" --memory=\"2g\" -e \"xpack.security.enabled=false\" docker.elastic.co/elasticsearch/elasticsearch:8.17.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f2893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch<9.0.0,>=8.0.0\n",
      "  Obtaining dependency information for elasticsearch<9.0.0,>=8.0.0 from https://files.pythonhosted.org/packages/33/62/f62e8a5c7c6f7b27481c9ffc248fb32078ad88878aa4f3731a83a14cc797/elasticsearch-8.18.1-py3-none-any.whl.metadata\n",
      "  Downloading elasticsearch-8.18.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /workspaces/llm-zoomcamp/venv/lib/python3.12/site-packages (from elasticsearch<9.0.0,>=8.0.0) (8.17.1)\n",
      "Requirement already satisfied: python-dateutil in /workspaces/llm-zoomcamp/venv/lib/python3.12/site-packages (from elasticsearch<9.0.0,>=8.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions in /workspaces/llm-zoomcamp/venv/lib/python3.12/site-packages (from elasticsearch<9.0.0,>=8.0.0) (4.14.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /workspaces/llm-zoomcamp/venv/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch<9.0.0,>=8.0.0) (2.4.0)\n",
      "Requirement already satisfied: certifi in /workspaces/llm-zoomcamp/venv/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch<9.0.0,>=8.0.0) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.5 in /workspaces/llm-zoomcamp/venv/lib/python3.12/site-packages (from python-dateutil->elasticsearch<9.0.0,>=8.0.0) (1.17.0)\n",
      "Downloading elasticsearch-8.18.1-py3-none-any.whl (906 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.3/906.3 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: elasticsearch\n",
      "  Attempting uninstall: elasticsearch\n",
      "    Found existing installation: elasticsearch 9.0.2\n",
      "    Uninstalling elasticsearch-9.0.2:\n",
      "      Successfully uninstalled elasticsearch-9.0.2\n",
      "Successfully installed elasticsearch-8.18.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install 'elasticsearch>=8.0.0,<9.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf52347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "869677bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ac5b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8064bae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version.build_hash value is dbcbbbd0bc4924cfeb28929dc05d82d662c527b7 \n"
     ]
    }
   ],
   "source": [
    "print(f\"version.build_hash value is {data[\"version\"][\"build_hash\"]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dadede86",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eba5cb",
   "metadata": {},
   "source": [
    "### Q 2\n",
    "\n",
    "Index the data in the same way as was shown in the course videos. Make the course field a keyword and the rest should be text.\n",
    "\n",
    "Which function do you use for adding your data to elastic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5422f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/llm-zoomcamp/week-1/minsearch.py:10: UserWarning: Now minsearch is installable via pip: 'pip install minsearch'. Remove the downloaded file and re-install it with pip.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f99ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch(\"http://localhost:9200\")\n",
    "index_name = \"llm-zoomcamp\"  # Use a valid, lowercase name\n",
    "\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    es_client.indices.create(index=index_name, body=mapping)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Delete the index if it already exists (optional, for a clean start)\n",
    "#if es_client.indices.exists(index=index_name):\n",
    "#    es_client.indices.delete(index=index_name)\n",
    "\n",
    "# Create the index with the mapping\n",
    "#es_client.indices.create(index=index_name, body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e5a25eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/llm-zoomcamp/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc57832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:07<00:00, 123.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e884630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "152eafbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:03<00:00, 299.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a68ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use es_client.index to add data to elastic.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We use es_client.index to add data to elastic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70778cd",
   "metadata": {},
   "source": [
    "### Q3. Searching\n",
    "Now let's search in our index.\n",
    "\n",
    "We will execute a query \"How do execute a command on a Kubernetes pod?\".\n",
    "\n",
    "Use only question and text fields and give question a boost of 4, and use \"type\": \"best_fields\".\n",
    "\n",
    "What's the score for the top ranking result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4f46061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top hits score for query 'How do execute a command on a Kubernetes pod?': 44.55304\n"
     ]
    }
   ],
   "source": [
    "query_0 = \"How do execute a command on a Kubernetes pod?\"\n",
    "\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": query_0,\n",
    "            \"fields\": [\"question^4\", \"text\"],\n",
    "            \"type\": \"best_fields\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es_client.search(index=index_name, body=query)\n",
    "top_hits = response['hits']['hits'][0][\"_score\"]\n",
    "\n",
    "print(f\"Top hits score for query '{query_0}': {top_hits}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6968ab",
   "metadata": {},
   "source": [
    "### Q4. Filtering\n",
    "Now ask a different question: \"How do copy a file to a Docker container?\".\n",
    "\n",
    "This time we are only interested in questions from machine-learning-zoomcamp.\n",
    "\n",
    "Return 3 results. What's the 3rd question returned by the search engine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f4d60dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd question: How do I copy files from a different folder into docker container’s working directory?\n"
     ]
    }
   ],
   "source": [
    "query_0 = \"How do copy a file to a Docker container?\"\n",
    "\n",
    "query = {\n",
    "    \"size\": 3, \n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [ \n",
    "                {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query_0,\n",
    "                \"fields\": [\"question\", \"text\"],\n",
    "                \"type\": \"best_fields\"\n",
    "        }\n",
    "    }\n",
    "    ], \n",
    "    \"filter\": [ { \"term\": {\n",
    "                \"course\": \"machine-learning-zoomcamp\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    }\n",
    "} \n",
    "}\n",
    "\n",
    "response = es_client.search(index=index_name, body=query)\n",
    "third_question = response[\"hits\"][\"hits\"][2][\"_source\"][\"question\"]\n",
    "print(f\"3rd question: {third_question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad8461",
   "metadata": {},
   "source": [
    "### Q5. Building a prompt\n",
    "Now we're ready to build a prompt to send to an LLM.\n",
    "\n",
    "Take the records returned from Elasticsearch in Q4 and use this template to build the context. Separate context entries by two linebreaks (\\n\\n)\n",
    "\n",
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a83561d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\\n\\n\".join([\n",
    "        context_template.format(\n",
    "            question= doc['_source']['question'],\n",
    "            text= doc['_source']['text']\n",
    "        ) for doc in search_results\n",
    "        ] )\n",
    "    \n",
    "    #context = \"\"\n",
    "    \n",
    "    #for doc in search_results:\n",
    "        \n",
    "    #    context = context + f\"section: {doc['_source']['section']}\\nquestion: {doc['_source']['question']}\\nanswer: {doc['_source']['text']}\\n\\n\"\n",
    "    \n",
    "    #prompt = context_template.format(question=query, context=context).strip()\n",
    "    \n",
    "    prompt = prompt_template.format(question = query, context=context)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87578446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b285a039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'llm-zoomcamp',\n",
       "  '_id': 'hjfnb5cBqjbfUwpbgod1',\n",
       "  '_score': 22.95559,\n",
       "  '_source': {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\",\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I copy files from my local machine to docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'}},\n",
       " {'_index': 'llm-zoomcamp',\n",
       "  '_id': '0jfnb5cBqjbfUwpbcIO_',\n",
       "  '_score': 22.95559,\n",
       "  '_source': {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\",\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I copy files from my local machine to docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'}},\n",
       " {'_index': 'llm-zoomcamp',\n",
       "  '_id': 'hzfnb5cBqjbfUwpbgod5',\n",
       "  '_score': 19.182852,\n",
       "  '_source': {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I copy files from a different folder into docker container’s working directory?',\n",
       "   'course': 'machine-learning-zoomcamp'}}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74cd0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(query_0, response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f73ec75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lenght of the promåpt is 1524\n"
     ]
    }
   ],
   "source": [
    "print(f\"The lenght of the promåpt is { len(prompt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028aa75f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
