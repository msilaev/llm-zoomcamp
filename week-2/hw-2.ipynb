{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf13c5f",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70fdaf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe89fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -q \"qdrant-client[fastembed]>=1.14.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d117ffb3",
   "metadata": {},
   "source": [
    "## Q1. Embedding the query\n",
    "Embed the query: 'I just discovered the course. Can I join now?'. Use the 'jinaai/jina-embeddings-v2-small-en' model.\n",
    "\n",
    "You should get a numpy array of size 512.\n",
    "\n",
    "What's the minimal value in this array?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c36bf3",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "docker pull qdrant/qdrant\n",
    "\n",
    "docker run -p 6333:6333 -p 6334:6334 \\\n",
    "   -v \"$(pwd)/qdrant_storage:/qdrant/storage:z\" \\\n",
    "   qdrant/qdrant\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d241299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9488cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:01<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "embedding_model = TextEmbedding(model_name=model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336224ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size (512,)\n",
      "Minimal element -0.11726373885183883\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "text_query='I just discovered the course. Can I join now?'\n",
    "\n",
    "embeddings = list(embedding_model.embed([text_query]))\n",
    "query_embedding = embeddings[0]\n",
    "\n",
    "# Now you can access the embedding\n",
    "print(f\"Embedding size {query_embedding.shape}\")  \n",
    "print(f\"Minimal element {np.min(query_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1efd47",
   "metadata": {},
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7823723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "986ecfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0000000000000002)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding.dot(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84ce13",
   "metadata": {},
   "source": [
    "## Q2. Cosine similarity with another vector\n",
    "Now let's embed this document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da67cbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9008528895674548 \n"
     ]
    }
   ],
   "source": [
    "doc = 'Can I still join the course after the start date?'\n",
    "embeddings_doc = list(embedding_model.embed([doc]))\n",
    "query_embedding_doc = embeddings_doc[0]\n",
    "\n",
    "print(f\"Cosine similarity: {query_embedding.dot(query_embedding_doc) } \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94abae10",
   "metadata": {},
   "source": [
    "## Q3. Ranking by cosine\n",
    "For Q3 and Q4 we will use these documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e146869",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae5b8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_text = []\n",
    "\n",
    "for doc in documents:\n",
    "    embeddings_doc = list(embedding_model.embed([doc[\"text\"]]))\n",
    "    query_embedding_doc = embeddings_doc[0]\n",
    "    embed_text.append(query_embedding_doc)\n",
    "\n",
    "embed_text = np.array(embed_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ef4dc",
   "metadata": {},
   "source": [
    "Compute the embeddings for the text field, and compute the cosine between the query vector and all the documents.\n",
    "\n",
    "What's the document index with the highest similarity? (Indexing starts from 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f087369",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query='I just discovered the course. Can I join now?'\n",
    "\n",
    "embeddings = list(embedding_model.embed([text_query]))\n",
    "query_embedding = embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41455412",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim =  embed_text.dot(query_embedding)  #np.dot(embed_text, query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d506143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76296845, 0.81823782, 0.80853974, 0.71330788, 0.73044992])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "753b9d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar document number is: 1\n",
      "The most similar document number is: Course - Can I follow the course after it finishes?\n"
     ]
    }
   ],
   "source": [
    "print(f\"The most similar document number is: {np.argmax(cos_sim)}\")\n",
    "\n",
    "print(f\"The most similar document number is: {documents[np.argmax(cos_sim)]['question']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46bcd5c",
   "metadata": {},
   "source": [
    "## Q4. Ranking by cosine, version two\n",
    "Now let's calculate a new field, which is a concatenation of question and text:\n",
    "\n",
    "full_text = doc['question'] + ' ' + doc['text']\n",
    "Embed this field and compute the cosine between it and the query vector. What's the highest scoring document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e973a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_text = []\n",
    "\n",
    "for doc in documents:\n",
    "    embeddings_doc = list(embedding_model.embed([doc['question'] + ' ' + doc['text']]))\n",
    "    query_embedding_doc = embeddings_doc[0]\n",
    "    embed_text.append(query_embedding_doc)\n",
    "\n",
    "embed_text = np.array(embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed2f5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim =  embed_text.dot(query_embedding)  #np.dot(embed_text, query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4469a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar document number is: 0\n",
      "The most similar document number is: Course - Can I still join the course after the start date?\n"
     ]
    }
   ],
   "source": [
    "print(f\"The most similar document number is: {np.argmax(cos_sim)}\")\n",
    "\n",
    "print(f\"The most similar document number is: {documents[np.argmax(cos_sim)]['question']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14bc1f0",
   "metadata": {},
   "source": [
    "## Q5. Selecting the embedding model\n",
    "Now let's select a smaller embedding model. What's the smallest dimensionality for models in fastembed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0236cc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with minimal dimension embedding: BAAI/bge-small-en, Dimensionality: 384 \n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "\n",
    "min_dim =np.inf\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model['dim'] < min_dim:\n",
    "        min_dim = model['dim']\n",
    "        min_model = model\n",
    "\n",
    "print(f\"Model with minimal dimension embedding: {min_model[\"model\"]}, Dimensionality: {min_dim} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be90df0",
   "metadata": {},
   "source": [
    "## Q6. Indexing with qdrant (2 points)\n",
    "For the last question, we will use more documents.\n",
    "\n",
    "We will select only FAQ records from our ml zoomcamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "664c4479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:01<00:00,  2.89it/s]\n"
     ]
    }
   ],
   "source": [
    "model_handle = \"BAAI/bge-small-en\"\n",
    "embedding_model = TextEmbedding(model_name=model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c84188",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_text = []\n",
    "\n",
    "for doc in documents:\n",
    "    embeddings_doc = list(embedding_model.embed([doc['question'] + ' ' + doc['text']]))\n",
    "    query_embedding_doc = embeddings_doc[0]\n",
    "    embed_text.append(query_embedding_doc)\n",
    "\n",
    "embed_text = np.array(embed_text)\n",
    "\n",
    "text_query='I just discovered the course. Can I join now?'\n",
    "\n",
    "embeddings = list(embedding_model.embed([text_query]))\n",
    "query_embedding = embeddings[0]\n",
    "\n",
    "cos_sim =  embed_text.dot(query_embedding)  #np.dot(embed_text, query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8138c32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest score: 0.8507919907569885\n"
     ]
    }
   ],
   "source": [
    "best_idx = np.argmax(cos_sim)\n",
    "print(f\"Highest score: {cos_sim[best_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d562f2",
   "metadata": {},
   "source": [
    "Alternative implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953d4ca",
   "metadata": {},
   "source": [
    "Run in terminal \n",
    "docker run -d -p 6333:6333 -p 6334:6334 \\\n",
    "   -v \"$(pwd)/qdrant_storage:/qdrant/storage:z\" \\\n",
    "   --name qdrant-container \\\n",
    "   qdrant/qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee147f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest score: 0.88934696\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "import requests\n",
    "\n",
    "# Connect to Qdrant (make sure it's running first!)\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "# Get ML Zoomcamp documents only\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "    \n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "# Use the model from Q5 (BAAI/bge-small-en - 384 dimensions)\n",
    "model_handle = \"BAAI/bge-small-en\"\n",
    "collection_name = \"ml-zoomcamp-qa\"\n",
    "\n",
    "# Create collection\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=384,  # bge-small-en dimensions\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add documents with question + text concatenated\n",
    "points = []\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    \n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=models.Document(text=text, model=model_handle),\n",
    "        payload={\"text\": doc['text']}\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "# Insert points\n",
    "client.upsert(collection_name=collection_name, points=points)\n",
    "\n",
    "# Search with Q1 question\n",
    "query = \"I just discovered the course. Can I still join it?\"\n",
    "results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=models.Document(text=query, model=model_handle),\n",
    "    limit=1,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(f\"Highest score: {results.points[0].score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0414c435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
